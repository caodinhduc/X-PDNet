# X-PDNet: Accurate Joint Plane Instance Segmentation and Monocular Depth Estimation with Cross-Task Attention and Boundary Correction
This is an implementation for X-PDNet: a multi-task learning framework for joint plane instance segmentation and depth estimation, which allows the respective task decoder to adaptively distill the cross-supplementary information for the specific task optimization. Besides, we propose Depth Guided Boundary preserving Loss to precise boundary region segmentation.
We also manually annotated over 3000 images, as a standard avaluation set for plane instance segmentation task

This repo is implemented by Pytorch based on [PlaneRecNet](https://github.com/EryiXie/PlaneRecNet), the detail code, introduction of training/testing, detail of proposed loss, and human-annotated data will be updated if we get acceptance of any upcoming conference.
### 1. General architecture
![Network Architecture](/images/X-PDNet.png)
### 2. We design a cross-task attention module, which leverages the idea of [PAD-Net](https://openaccess.thecvf.com/content_cvpr_2018/papers/Xu_PAD-Net_Multi-Tasks_Guided_CVPR_2018_paper.pdf) with improvement allowing model adaptive with different scales of plane instance mask

![attention](/images/attention.png)
### 3. We focus on problem of incorrect segmentation at boundary regions, analyze the limitation of obtaining boundary from current groundtruth in designing the traditional boundary preserving loss

![coarse](/images/coarse.png)
### 4. Then propose Depth Guide Boundary Preserving Loss, that alleviates the problem of imperfect instance segmentation ground truth mask
Since my paper is under review, I cannot share more about this
### 5. Manually annotated dataset for evaluation
We contribute 3000 images with over 30000 instance masks labeled by human for reliable evaluation of plane instance segmentation task
![result1](/images/label.png)
# Result
### 1. Comparison with existing methods

![result1](/images/result1.png)
### 2. Quatitative comparison of X-PDNet with baseline
Visualization of effectiveness of Cross Attention Design on images from ScanNet dataset. For each example image, the first row is output of PlaneRecNet while the second row generated by X-PDNet, (Normal is recovered from predicted depth).

![result2](/images/result2.png)

### 3. Evaluation of Depth Guided Boundary Preserving Loss on both original and human labeled annotation

![result3](/images/result3.png)
### 4. Compare the effectiveness of proposed DGBPL to vanilla method
![result4](/images/result4.png)